library(plyr)
library(RColorBrewer)
library(tidyverse)
library(rgdal)
library(parallel)
library(plotrix)
library(ggplot2)
library(reshape2)
library(sf)
source("Consumer_Vunerability_library_v13.R")
dir.create("figures")


# Get data ----------------------------------------------------------------------------

# Load data
############
#The dataset and lookup table was downloaded from http://geogale.github.io/2011OAC found in the “Input Data” section under the title “2011 OAC 167 Initial Variables Dataset”.
############
oa_data <- readr::read_csv("2011_OAC_Raw_uVariables.csv")
variable_choices <- readr::read_csv("K-means_version_5_variables.csv")
lookup_table <- readr::read_csv("2011_OAC_Raw_uVariables_Lookup.csv")
#View(lookup_table)

# Prepare raw data to pecentages-------------------------------------------------------
cv_pct_data <- oa_data %>%
  tibble::add_column("Rate" = 100) %>%  # Add a column of just 100's for use in percentage calcs below when already dealing with rates
  count_to_percentage(variable_choices) %>% # Create percentages
  base::replace(is.na(.), 0) %>%  # Replace any nan's with 0's 
  dplyr::mutate(u062_u065 = u062 + u065) %>%  # Combine married/cohabiting
  dplyr::mutate(u063_u066 = u063 + u066) %>%  # Combine married/cohabiting
  dplyr::mutate(u064_u067 = u064 + u067) %>%  # Combine married/cohabiting
  dplyr::mutate(u049_u050 = u049 + u050) %>%  # Combine english skills
  dplyr::mutate(u127_u129 = u127 + u129) %>%  # Comnine students
  dplyr::mutate(u095_u096 = u095 + u096) %>%  # combine occupancy rating
  dplyr::select(-u062:-u067) %>%  # Remove married/cohabiting
  dplyr::select(-u047:-u050) %>%  # Remove english skills
  dplyr::select(-u127) %>%  # remove students
  dplyr::select(-u129) %>%  # remove students
  dplyr::select(-u095:-u099)  # remove occupancy

cv_pct_data <- cv_pct_data[, order(names(cv_pct_data))] # sort colums by name # sort colums by name

# Make lookup maps
keys <- as.list(c(variable_choices$VariableCode, 
                  c("OA", 
                    "u062_u065",
                    "u063_u066", 
                    "u064_u067",
                    "u049_u050",
                    "u127_u129",
                    "u095_u096"
                    )))

values <- as.list(c(variable_choices$VariableLabel, 
                    c("Output Area", "Married or cohabiting: No children", 
                      "Married or cohabiting: Dependent children", 
                      "Married or cohabiting: No dependent children",
                      "Poor English Skils",
                      "Student",
                      "Crowded houseing"
                      )))

lookup_map <- list2env(setNames(values, keys), envir = new.env(hash = TRUE))
rev_lookup_map <- list2env(setNames(keys, values), envir = new.env(hash = TRUE))



# Transformation ----------------------------------------------------------------------

# Calculate inverse hyperbolic sine
cv_ihs <- ihs(cv_pct_data)

# Standardisation ---------------------------------------------------------------------
cv_ihs_z <- z_scores(cv_ihs)

# rename variables to give full names
names(cv_ihs_z) <- purrr::map_chr(names(cv_ihs_z), function(x) lookup_map[[x]])

# Corrolation-------------------------------------------------------------------------
cor_mat <- cor(cv_ihs_z)
high_cor <- purrr::map(colnames(cor_mat), cor_cutoff, 0.6)
high_cor[purrr::map_lgl(high_cor, ~length(.) > 1)]

# PCA ----------------------------------------------------------------------------------

# Perfom principle component analysis
pca_obj <- stats::princomp(cv_ihs_z, scores = T)


# Look at variation each componet explains
pca_obj$sdev^2/sum(pca_obj$sdev^2)
plot(pca_obj$sdev^2/sum(pca_obj$sdev^2),
     #main="Variance explained by priciple components",
     xlab="Principal components", 
     ylab="Variance", 
     type = "o")
dev.copy(pdf, "figures\\pca_elbow.pdf")
dev.off()

# Look at cumulative variation
cumsum(pca_obj$sdev^2/sum(pca_obj$sdev^2))
plot(cumsum(pca_obj$sdev^2/sum(pca_obj$sdev^2)), 
     #main="Cumulative variance explained by priciple components",
     xlab="Principal Components", 
     ylab="Cumulative Variance",
     type = "o")
dev.copy(pdf, "figures\\pca_cumulative.pdf")
dev.off()


# When IHS transformation is used the first 25 priciple explains 81% of variation
num_pc <- 10
#Loadings
load <- with(pca_obj, unclass(loadings))
loadings <- sweep(abs(load), 2, colSums(abs(load)), "/")

par(mar=c(15, 5,1,1))
barplot(rowSums(abs(load[,1:num_pc])), las=2, cex.names = 0.6, #main = "Sum of Loadings for Principal components 1 to 10", 
        ylab = "Sum of Principal Componet Loadings", border = "blue")
dev.copy(pdf, "figures\\pricipal component loadings.pdf") # resize to fit before saving
dev.off()

# Clustering -------------------------------------------------------------------------

# k-means with different numbers for k -> 1:n to choose an appropiate k
iter = 1:25
#k_choice_clust_list <- k_comparison(pca_obj$scores[, 1:num_pc], iter, 25) # Uncomment
#scree(k_choice_clust_list, iter, "All data") # Uncomment

# Small clusters start after a k of ? and elbow plot shows decreasing WSS at around ?
num_clusters <- 6

nstart=100
set.seed(2494)
system.time(
  k_means_obj <- k_means(num_clusters, pca_obj$scores[, 1:num_pc], nstart)
)

cluster_names <- c("Students and Young Professionals", "On a Budget", "Prosperous Professionals",
                   "Well Established", "Vulnerable Communities", "Vulnerable Pensioners")

# Compute a data frame (one row per cluster) containing the means of each variable in that cluster
cluster_zscores <- plyr::ddply(cv_ihs_z, .(k_means_obj$cluster), numcolwise(mean))[, -1]
row.names(cluster_zscores) <- cluster_names

### same steps for Sub groups
cluster_selection <- tibble::as_tibble(cbind(pca_obj$scores[, 1:num_pc], cluster=k_means_obj$cluster, OA=oa_data$OA))
#map(1:num_clusters, run_kmeans_comp_subgroup, cluster_selection, num_pc)  # Uncomment

sub_k <- c(4, 5, 5, 4, 8, 5)
sub_groups <- map(1:num_clusters, function(subgroup, data) dplyr::filter(data, cluster==subgroup), cluster_selection)
sub_groups_kmeans <- purrr::map2(sub_groups, sub_k, run_kmeans_subgroup, nstart)
sub_cluster_zscores <- purrr::map(1:num_clusters, avg_z, sub_groups_kmeans, k_means_obj, cv_ihs_z)

cluster_z_diff <- purrr::map(1:length(sub_cluster_zscores), 
                      function(x) cluster_difference(sub_cluster_zscores[[x]], cluster_zscores[x,]))

# produce radial plots --------------------------------------------------------------

# groups to global
purrr::map(1:nrow(cluster_zscores), 
    function(x) radial_plot(cluster_zscores[x,], cluster_names[x], min_max=c(-3,3), "Group to global \n mean z-score\n"))

# sub-group to global
#map2(sub_cluster_zscores, cluster_names,
#     function(x, name) map(1:nrow(x), 
#                           function(y) radial_plot(x[y,], paste(name, "- Sub-group", y), min_max=c(-6,6), "Subgroup to global \n mean z-score\n")))

# sub to global and sub to group diff (red line is global, blue line is difference between group and subgroup)
purrr::pmap(list(sub_cluster_zscores, cluster_z_diff, cluster_names), 
     function(global, diff, name) purrr::map(1:nrow(global), 
                           function(i, global, diff, name) radial_plot(rbind(global[i,], diff[i,]), paste(name, "- Sub-group", i), min_max=c(-6,6), c("Subgroup to global \n mean z-score\n", "Subgroup to group \n mean z-score\n")),
                           global, diff, name))

# all subgroups to global means
purrr::map(1:length(sub_cluster_zscores), 
    function(x) radial_plot(sub_cluster_zscores[[x]], paste(cluster_names[x], "- Subgroups"), min_max=c(-6,6), purrr::map(1:nrow(sub_cluster_zscores[[x]]), 
                                                                                                                   function(x) paste("Subgroup", x))))

# produce heatmap ----------------------------------------------------------------------
sub_cluster_zscores <- map2(sub_cluster_zscores, cluster_names, rename_rows)
#pdf("figures\\group_heatmap.pdf", width = 250, height=350)
create_heatmap(rev(cluster_zscores), 6, c(16,7)) # If dendogram renders incorrectly - clear all plots and run this line again
dev.copy(pdf, "figures\\group_heatmap.pdf") # resize to fit before saving
dev.off()

subcluster_data_frame <- rbind(sub_cluster_zscores[[1]], sub_cluster_zscores[[2]], sub_cluster_zscores[[3]], sub_cluster_zscores[[4]], sub_cluster_zscores[[5]], sub_cluster_zscores[[6]]) 
subcluster_data_frame <- rev(subcluster_data_frame)
create_heatmap(subcluster_data_frame, 31, c(20,7)) # If dendogram renders incorrectly - clear all plots and run this line again
dev.copy(pdf, "figures\\subgroup_hetmap.pdf") # resize to fit before saving
dev.off()



# shape file ------------------------------------------------------------------------
clust_tibble <- cluster_tibble(oa_data, k_means_obj, "cluster")
subcluster_tibbles <- purrr::map2(sub_groups, sub_groups_kmeans, cluster_tibble, "subcluster")
shape <- sf::st_read("UK_Shapefiles/2011_OAC.shp")
shape <- sf::st_transform(shape, 4326)

shape <- shape[c(-2, -3, -4)]
shape <- dplyr::right_join(shape, clust_tibble)
shapes <- purrr::map(subcluster_tibbles, left_join, shape)
shape <- dplyr::left_join(shape, rbind(shapes[[1]][, c(1, 2)], shapes[[2]][, c(1, 2)], shapes[[3]][, c(1, 2)], shapes[[4]][, c(1, 2)], shapes[[5]][, c(1, 2)], shapes[[6]][, c(1, 2)]), by="OA_SA")
shape$cluster_subcluster <- paste(shape$cluster, shape$subcluster, sep = "_")

sf::st_write(shape, dsn = "sub_shape.shp",  driver = "ESRI Shapefile")

# Compare clusters to oac Clusters -------------------------------------

# Second Closest Cluster Comparison 
load("oac_k_means_obj")
load("oac_input_data")

cv_distances <- find_distances(pca_obj$scores[,1:num_pc], k_means_obj)
oac_distances <- find_distances(oac_input_data, oac_k_means_obj)

levels <- c(0.01, 0.1, 0.5, 1:10)
levels <- seq(from=0, to=10, by=0.01)
cv_percent_nearest <- percent_nearest(cv_distances, levels)
oac_percent_nearest <- percent_nearest(oac_distances, levels)

data_long <- reshape2::melt(tibble::tibble(percentage = levels,
                         "Consumer Vulnerability Classification" = cv_percent_nearest,
                         "Output Area Classification" = oac_percent_nearest), 
                  id="percentage")

ggplot2::ggplot(data_long,
       aes(x=percentage, y= value, colour=variable)) +
  geom_line() +
  labs(title="Second Closest Cluster Comparison", 
    y="Percentage of Output Areas",
    x="Percentage Difference of Second closest Centroid to Assigned Centroid")
dev.copy(pdf, "figures\\Second Closest Cluster Comparison.pdf")
dev.off()

# Cluster Membership Diversity comparison (Simpson's diversity index)
div_lev <- c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)
div_lev <- c(0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89)
div_lev <- seq(from=0, to=1, by=0.01)
cv_diversity <- 1 - (apply(select(cv_distances, -ncol(cv_distances)), 1, function(x) sum(( x / sum(x))^2)))
oac_diversity <- 1 - (apply(select(oac_distances, -ncol(oac_distances)), 1, function(x) sum(( x / sum(x))^2)))

cv_diversity_levels <- map_dbl(div_lev, function(x, y) sum(y > x) / length(y) * 100, cv_diversity)
oac_diversity_levels <- map_dbl(div_lev, function(x, y) sum(y > x) / length(y) * 100, oac_diversity)

data_long_d <- melt(diversity_data <- tibble(percentage = div_lev,
                                             "Consumer Vulnerability Classification" = cv_diversity_levels,
                                             "Output Area Classification" = oac_diversity_levels), 
                    id="percentage")

ggplot2::ggplot(data_long_d,
       aes(x=percentage, y= value, colour=variable)) +
  geom_line() +
  labs(title="Cluster Membership Diversity Comparison", 
    y="Percentage of Output Areas",
    x="Diversity Index of Output Area")
dev.copy(pdf, "figures\\Cluster Membership Diversity Comparison.pdf")
dev.off()



############################
##For presentation
a <- subcluster_data_frame
names(a)

a <- a[,c(13:42)]
a <- a[c(10:18,
         1:4,
         5:9,
         19:31),]

a
library(tm)


row.names(a) <- unlist(map(rownames(a), function(x) removeWords(x, "Subgroup")))
names(a) <- c(colnames(a[,1:11]), "Highest qualification: Level 1 or 2", colnames(a[,13:30]))
a
create_heatmap(a, 31, c(16,7))


